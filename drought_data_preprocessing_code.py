# -*- coding: utf-8 -*-
"""drought_data_preprocessing_code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11MZ485hKL-i5Vxoh3S41M72yhWL1xv12

# Mount the google drive
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)
import numpy as np
import pandas as pd

"""# Read the raw file"""

path = '/content/drive/Shareddrives/1:1 Clarisse/drought/train_timeseries/train_timeseries.csv'
df = pd.read_csv(path)
print('Number of samples: ', len(df))

"""# View the dataframe"""

df.head()

"""# Drop the NA values"""

df_noNa = df.dropna(how='any')

"""# Find the max and min values in the score columns"""

print(df_noNa["score"].max()) #finds max
print(df_noNa["score"].min()) #finds min

"""# Convert the score value to drought levels specified by https://droughtmonitor.unl.edu/ """

df_noNa["score"] = pd.cut(x = df_noNa["score"], bins = [0, 1, 2, 3, 4, 5], labels = ['D0', 'D1', 'D2', 'D3', 'D4'])

"""# View the number of unique values in the label column

# Subsample the number of samples in each category to 56935, which is what the category with lowest samples (D4) has.
"""

sample_per_category = 56935
balanced_df_noNa = pd.DataFrame()
for category in list(df_noNa['score'].unique()):
    subset_data = df_noNa[df_noNa['score']==category]
    if (len(subset_data)>sample_per_category):
        subset_data = subset_data.sample(n=sample_per_category, replace=False)
    balanced_df_noNa = pd.concat([balanced_df_noNa, subset_data], ignore_index=True)
balanced_df_noNa.to_csv('/content/drive/Shareddrives/1:1 Clarisse/balanced_Drought_Data_56935.csv', index= False)